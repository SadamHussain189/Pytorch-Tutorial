{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch\n",
    "## Before You Start\n",
    "\n",
    "To run this tutorial, you'll need to install PyTorch, TorchVision, Matplotlib, and TensorBoard.\n",
    "\n",
    "With `conda`:\n",
    "\n",
    "`conda install pytorch torchvision -c pytorch`\n",
    "`conda install matplotlib tensorboard`\n",
    "\n",
    "With `pip`:\n",
    "\n",
    "`pip install torch torchvision matplotlib tensorboard`\n",
    "\n",
    "Once the dependencies are installed, restart this notebook in the Python environment where you installed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we'll be training a variant of LeNet-5 against the Fashion-MNIST dataset. Fashion-MNIST is a set of image tiles depicting various garments, with ten class labels indicating the type of garment depicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"./runs/fashion_mnist_experiment_1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Images in TensorBoard\n",
    "\n",
    "Let's start by adding sample images from our dataset to TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoBUlEQVR4nO3de3RU1fk38CfchgRCBEIyDAkYIHIRQUw0BVHihbAQpS61iihgWW1FwBJZlqtdpv40odRSbS1UXRbtsoitIooLKaFA0KJcAhGEcpMA4RIityQiJED2+0ffzGJ/z2F2hpmQneT7WYs/njlnzpzZ55LN7Oc8O0IppYSIiIjIAk3qegeIiIiIqrFjQkRERNZgx4SIiIiswY4JERERWYMdEyIiIrIGOyZERERkDXZMiIiIyBrsmBAREZE12DEhIiIia7BjQkRERNaotY7JvHnzJCkpSVq2bCkpKSny+eef19ZHERERUQPRrDY2+v7770tmZqbMmzdPbr31Vnn99ddl2LBhsmPHDuncuXPA91ZVVcmRI0ckOjpaIiIiamP3iIiIKMyUUlJeXi4+n0+aNLny3z0iamMSv7S0NLnppptk/vz5/td69eol999/v+Tk5AR876FDhyQxMTHcu0RERERXQVFRkSQkJFzx+8P+i0llZaXk5+fL9OnTtdczMjJk3bp1jvUrKiqkoqLCH1f3k1588UVp2bJluHePiIiIasG5c+fkueeek+jo6JC2E/aOyfHjx+XixYsSHx+vvR4fHy/FxcWO9XNycuQ3v/mN4/WWLVtKZGRkuHePiIiIalGoaRi1lvyKO6aUct3ZGTNmSGlpqf9fUVFRbe0SERERWS7sv5jExsZK06ZNHb+OlJSUOH5FERHxeDzi8XjCvRtERERUD4X9F5MWLVpISkqK5Obmaq/n5ubKwIEDw/1xRERE1IDUyuPCU6ZMkdGjR0tqaqoMGDBA3njjDTl48KCMHz++Nj6OiIiIGoha6Zg88sgjcuLECXnhhRfk6NGj0qdPH1m2bJl06dIlLNufMGFCWLYTjKqqKi3GfJlgk32w4By+/5prrtHiQ4cOaTH++tSmTZuAn1eTp8Kvdt2YefPmBVwe7uOMbRCO73v8+HEtfu+997T4pptu0mIczrxw4YIWX7x4UYtPnDihxXjeTJo0SYtjYmIMe2wW7na62seZ6kZ9PM6XPhEqIvL1119r8fLly7U4PT1di2+//fagPg+3v2fPHi0eOnSoFof6dIvI1b+ew6FWOiYi/zsJbTwRiYiIyF6cK4eIiIiswY4JERERWaPWhnLqOxyXC6Xuv4jIwoULtXjBggVajLkEPXr00OIVK1Zocc+ePbX4P//5T8DPr8m4Ym3kYNSlcHyf/fv3a/EHH3ygxfhYfKdOnbR48eLFWvzDDz9oMRYRbNGihRZ36NBBi5OSkrQYzyN8/z333KPF1157rZi41SAKtJyoNpjy4vA8xPysd9991/Gev/3tb1ocFRWlxWfOnNHiZs30P5EfffSRFpeUlGhxXFycFm/dulWL8frDvEvM38AcmNTUVC0eO3asFmNOm0j9vF75iwkRERFZgx0TIiIisgY7JkRERGQN5phcBo7L4dgj5hrgWCLWHUE4djhu3DgtxpmVFy1apMVnz57V4pdfflmLsb7GLbfcosX33nuvY58wP6G+5xaY9nfLli2O19avX6/FZWVlWox1Bfr376/FpaWlWoxjyu3atdNirDuC5wWOgX///fdajFOL43Ksw4DnsYjI8OHDtRjzl+rbcaeGwZTnd+zYMS0eOXKkFuM9UkSkbdu2Woz3PLy+cR8w5wuv7/Pnz2tx9+7dtRivZ6yPhXWN8Dvs3r1bi3/2s59pcWZmpqAxY8Y4XrMdfzEhIiIia7BjQkRERNZgx4SIiIiswRyTy9i5c6cWz5o1S4txrLB58+YBlx8+fFiLMQflr3/9qxZjLsDDDz8ccPmuXbu0GOfOWb16tRavWbNG0HPPPafF+Ex+fc85wZyS+fPnO9bp3bu3FpvqjHz33Xda7PF4tBjHxTFn5fTp01qM55GprgIeE9w/HLPGOZhERJYuXarFmN9Uk9onROFmqh317LPPajHma7jNzYbrmHI88B6Hy/F6xWsH18ccMpNWrVppMd7XMWcG62WJiDz00ENajH+bbMRfTIiIiMga7JgQERGRNdgxISIiImuwY0JERETWYPLrZbz++uta3LRpUy3GJEJMSsTJ2q677jot7tevnxbn5uZqca9evbS4T58+WoxJV5iEiUlSmJR55MgRQW+//bYWT506VYvrW7IrWrVqlRZj4puIeeIwTFbF9U0JwngccOIxhAmAponL8DtVVlZqMSbHijj3ee3atVrM5FeywcGDB7UYH1DACTTx3K8JvI/j9dW6dWstxoKJWGARC7LhZK24Pt7X8drE5FncX7d72scff6zFjz76qGMd2/AXEyIiIrIGOyZERERkDXZMiIiIyBrMMRHn2KWISFFRkRbjWCGO/eF4JhbawbF9zAG57bbbtBiL4OBYJ07Whuvj/tRkvDU/P1+LMU+mPhTmCQTzanA8V0Rk+/btWpycnKzFOEmXqaASfoZpDBnheYO5Tnhccf/Qnj17HK/huYjnPpENvvnmGy3Gc/3cuXNajNemiPP6wRwuvB7xvovXSmJiohZjDgpOwocFGzHHBHPIcH9MuYxu179bPqHt+IsJERERWYMdEyIiIrIGOyZERERkDeaYiMiXX37peA3rTeBYII5fRkdHa3Gwk0WdOnVKi3Gs0rR/ODaJY6mYk4LjsSLOCeMw5wTzYOqb48ePa7HP53Os8+233waMMdcIzwM8Lngc8Dww1TEx5QrhGDnmAZWXl2sxTiYp4qzFgDVxiGywefPmgMvxHtq+fXvHOnh9IszhwOsb8xExZwsn3cPr25R7iPcHvL4xhwRzWNwwx4SIiIgoBOyYEBERkTXYMSEiIiJrMMdE3OuY4PPmOO5uyvHAsUEcu8Q4JiZGi0PNRcCxTMyRwc8Tcc7/U9/rWWANgNWrV2vxz3/+c8d78Ljt379fizEfAz/DlFOCuUW4Po4Z43Ick8ZcIRxXx/PWbUwa9wnXwXMP94noasAaQ3gPxpoebvkkWEcIz31THRHM/cOcElMdI7zvI/w8fH9JSYkW43fGXEcRkeLi4oCfaSP+YkJERETWYMeEiIiIrBF0x2Tt2rVy3333ic/nk4iICFmyZIm2XCklWVlZ4vP5JDIyUtLT0x0/wRERERG5CTrH5MyZM9KvXz/56U9/Kg8++KBj+Zw5c2Tu3Lny9ttvy3XXXScvvviiDBkyRHbt2uU6/mWDrVu3Ol7D3IDTp09r8c6dO7V46NChWmyaUwXH7SsqKrQY61GYxkYx9wDHHvHz3GpVYF0P/M71zaFDh7QY84bc6pjs3btXi3fv3q3F3bp102IcxzbVGTGNOWPdETyOmEOC5w1+fk1yTHAfcZtYA8ctP4motu3atUuLMd8Dr50TJ044thEXF6fFeG5j/hRe33hfN+WkYIzXlinnBGFOGd4f2rZt63jPyZMng/oMGwTdMRk2bJgMGzbMdZlSSl555RWZNWuWPPDAAyIi8s4770h8fLwsXLhQnnzyydD2loiIiBq0sOaYFBYWSnFxsWRkZPhf83g8MnjwYFm3bp3reyoqKqSsrEz7R0RERI1TWDsm1Y8lxcfHa6/Hx8df9pGlnJwciYmJ8f/DaaSJiIio8aiVOiZu4274WrUZM2bIlClT/HFZWdlV75zg2KSIM8cDx+FxXhmcgwTrXeBYIm4Pc1pw/BTbD2PMOcGxx6SkJC12G3/F9+Az8/UNzhGBNQfc6nFgrg52sk21Xdq0aRNwe5hrhPC8wOOKn495MzgGjfOH4Hnr9hm4DzjHEHNMnDCX4HL3u8s5cOCAFmMuUM+ePa9sxxoQzHmLjY3VYjyPMRZxXo+mOcaChdcOnhe4HI8z3h9MfydM9bJEnLl29UFYOyZer1dE/vfLSceOHf2vl5SUOG7w1Twej3FiJSIiImocwjqUk5SUJF6vV3Jzc/2vVVZWSl5engwcODCcH0VEREQNUNC/mHz//ffaI5WFhYVSUFAg7dq1k86dO0tmZqZkZ2dLcnKyJCcnS3Z2tkRFRcmoUaPCuuNERETU8ATdMdm0aZPccccd/rg6P2Ts2LHy9ttvy9SpU+Xs2bMyYcIEOXXqlKSlpcmKFSusrWEi4j4WieOXOBaIY4edOnXSYnxe3fQ8PC7HsUSsT4G5BDg2ijkl+Cy7Wx2TDh06aLFbHkp9gnk/WMMA21DEeS6MGDFCi5ctW6bFlw5ZijjHrHFMG8eATfPQ4HmBuU+mejv33nuvFmObiJhrOdT3ejbhYMohMeWULF26VIt//etfa3FCQoIWf/vtt1q8adMmLcZ8KVPuQU3Wweth4sSJWjxz5kwtxpo+tQ3vwXgt4fdzyx3Ec9u0DVOOiKmOCcL3Y4x5fpgCgdcqfj7WSRJx/u2oD4LumKSnpwds/IiICMnKypKsrKxQ9ouIiIgaIc6VQ0RERNZgx4SIiIisUSt1TGyHY244rijirNWwefNmLcZcBMwpMdWjwLFBzDkxjQebxjrx/TjGXf1o96UwXwJrYNQ3mBuBtWXcxqCx8vCQIUO0+OWXX9biHj16aDEeRxy3N+WU4HI8jqYxbRyDvvHGG7UYa7uIiHTt2tXx2qXqez0b07i/iDlHxLR8z549Woy5SXjPSUtL02LMDcAckszMTC1+8803tdgtpwSZ1pkxY4YWv/fee1qMNXNee+0142eGAu+ZpnlokFvNHoQ5YG5/C4JRk3PtUli3pLS0VIvxfrJv3z4txmvX7fPdculsx19MiIiIyBrsmBAREZE12DEhIiIiazTKHBPT2KWIc1wdx+ZNOSUY4xizaU4GfL4e34/bx/wJzK/o27evFmMugoizRgbmW9SkVoJNTHO8uOWY4Ng+1j7BMWAcv8XzAs8tPPdwjNnUxvh+nFPJ9P727dsLMtXccat9cjUFm2eDwnGeHjt2TIvnzJmjxRs3btTifv36aTHmO2AdIby+MZ/j4MGDWvz73/9eizGnBc9bEec954MPPtBiPM6pqalafLVzFfAeZqolg98P6564vceUq4exKUfM9H48l/E44z0Xc49MOTBuy/E1rJWC930b2P2XhYiIiBoVdkyIiIjIGuyYEBERkTUaZY4JzgGDeQUizrH8lJQULf7yyy+1GHMPcI4DHJvE5+dxH3A8FfMAcGwSl2PuAq7vNg8OjpfimDLmpbRp08axDZvgMcE2xrFWEWduj2muG4xN4+CmMW08Bqb1TTBfxC3HBM9NPHfccnGuJlOOSLBtIvK/yUcvhXV+Vq1apcWdO3fWYmzX0aNHa/HChQu1GM9FzOfAubZwfcw1ePXVV7X4nXfe0WK3NsPjivkMuA+4/vLlyx3brE14XiK3Oc4u5VarCe9Z2AZ4XIO9fk3XP+Z7mOoYYV5cly5dtBhzk9zuaXju4PXMHBMiIiKiANgxISIiImuwY0JERETWaJQ5JlhDwG2sEsfir7nmGi1++OGHtfiZZ57R4gcffFCLMRcBxxJxH0zPy+NYJ66PY6n5+flanJiYKAj3AcdbcfzS9hwT3F/8Pm6wnU25P3hcTWPIpnwJXG6qS2IaY8bcoujoaMdnmuZxquscE/x8nD8E69Xg8rfeesuxzaKiIi1u27atFvfv31+L8Tj897//1eKPP/5Yi3EOE5/PF3Af9+/fr8V4nPA8i42NDbi+W20XPDew9hGeS3juFxcXazHWVgk3zHHD89KUY5Kenu54zVTzxlRfCu+zwdbUMa2PeT143IcOHarFS5Ys0WI8hiLO44h5NZgPaQP+YkJERETWYMeEiIiIrMGOCREREVmDHRMiIiKyRqNMfjUV3hJxJtx16NBBizGREhO1MOkQJ5TCwjn4fix6g/uMSVEIk7S6d++uxbt373a8p3fv3gG3iUXcbIeJYFgszQ0mp+FxwHbHZDmMTQl6wRaRwvMO9weTKnF9t4RlTAbHc9e0j6FatmyZFq9du1aL8drDNjl58qQW43Hv06eP4zNxkr19+/ZpMU7aiZP4mQpx4XHApEa8/vHzMFEVzyuc4A6T893uaZiAe91112nxzp07tRgLKuJEoG6JluGEEx/iuY7nAR4jLIopIrJr1y4tDnUSPhRsAUW8p+Lki3hedOvWTYvx2nRLvsVzta6T2WuCv5gQERGRNdgxISIiImuwY0JERETWaJQ5JqbxYhHnGC7maODYYevWrbUYxxJxIiVToR0co8b3Y4xjnziWOm7cOC3+17/+JQjHdDHXAPfJdpjXg8fILU8H1zEdNxxTNhVcM41h43lgGpM2FYTC/cHCXyIie/fuDbgPpjyZUGExQ/z8HTt2aDEeI5x8DoulueVCHDhwQIsxlwg/A5djcTHM6cA2xXbH8+b6668PuH28Fk3FxjA3QcSZM7J161YtxnMFC7CdOnVKizEvLtywEBjmiOG1gPenpKQkxzbxO+P1jUzXa7ATSJqud1M+CE4+iW3gdk8z5aHZiL+YEBERkTXYMSEiIiJrsGNCRERE1miUOSY46ZfbOH1JSYkW4zg4jneaJltDptwD/Hwc78VxQtwe7h+OQeP2RJx5KaZ9wrwb22Cb4Di92xi52yR3l8I2MU3OaMoBMZ03mNuAeQK4P6baElhPQ8SZT2WaUDLc0tLSAsY4eRzWPfnss8+0eOXKlVrsVp8H64RgG+BxMeUzIFy+Zs0aLca8mF69emkxnjeYL4XnHeYiuOVXYLviuRBsDQ/8DKw/Eyq832AeD57ruL9Yt0XEeRwxxwRzPoKdlC9Ypveb8vwwxvuFiDN3sD7Uo+IvJkRERGSNoDomOTk5cvPNN0t0dLTExcXJ/fff7/hftlJKsrKyxOfzSWRkpKSnp8v27dvDutNERETUMAXVMcnLy5OJEyfKV199Jbm5uXLhwgXJyMjQfiqaM2eOzJ07V1577TXZuHGjeL1eGTJkSL0og0tERER1K6gck+XLl2vxggULJC4uTvLz8+X2228XpZS88sorMmvWLHnggQdEROSdd96R+Ph4WbhwoTz55JPh2/MQ4Fip27PfOKcIjm/i/Bw4VwWOWePz6Th2ibkFpnwIXB9zI7COAY7Her1eQQUFBVqM3xlrPwwcONCxDZuY8jfcxlrdcm8uFWw9GtwHzN/AXAJcH/M7MMbtmXIfYmNjHa+Z8pFM+VKhMtVNwXMVa/JgjNyOM46743+csB3Xr1+vxfPnz9dizLfAeWWwtgrmmOBxwTbBexTmGuHcOzgXkIg5J8OUb4Hnnmm+rlAdPnxYi/E74vxh+H3wHirivG9jHgp+x1DrliDT/QGPAV4L2AZ4DNzmA8N9xvwqG4V0x6k+Mapv5oWFhVJcXCwZGRn+dTwejwwePFjWrVsXykcRERFRI3DFXV6llEyZMkUGDRrkn72zOns+Pj5eWzc+Pt7xv+1qFRUV2v9osNofERERNR5X/IvJpEmTZOvWrfLee+85lrn9vH25n8BycnIkJibG/y8xMfFKd4mIiIjquSv6xeTpp5+WTz75RNauXSsJCQn+16vHgouLi6Vjx47+10tKShy/olSbMWOGTJkyxR+XlZXVeucEx5zdnv3G2gk33nijFn/66adajGPImDuAY9aYc4J1CuLi4gK+3zRnC+aknDhxQovdxqCzs7O1+K677tJinCvDdqZj4DYHDOYWIdPcGiY4pmyqk2B6P46Jm2oUYN6QiDlPJtTvbGLKdUB43Ext6JYLgblEptwirNnz2GOPaTFeb6Z6GKZzEY8zro/XO95f3XKNioqKtNg03xe2G15PmO8Qbpj3g9cm3tPw+7jtn2luGWw3XI7tHuxcOqbzwlTfCmvP4LVSk7yf2p77KhyC+sVEKSWTJk2SxYsXy6pVqxwJX0lJSeL1eiU3N9f/WmVlpeTl5V02UdLj8UibNm20f0RERNQ4BfWLycSJE2XhwoXy8ccfS3R0tP9XhZiYGImMjJSIiAjJzMyU7OxsSU5OluTkZMnOzpaoqCgZNWpUrXwBIiIiajiC6phUPyKXnp6uvb5gwQJ54oknRERk6tSpcvbsWZkwYYKcOnVK0tLSZMWKFcZS30RERERBdUxqMh4eEREhWVlZkpWVdaX7VOswn8NtTPu7777T4m7dumkxPmWEY4+mOVIwxwTH/nHM2jQ3D66PdVVwPNZtLg0cf8U42HyIuoZj5jXJTXCbSyYYpjoHplwCPG9w/WBrTSC35aZaKaHWbgi32q6fcSVCPW/Cze2ehvcw2+H9B++BWJcF76ludUwwh8RUTwpjXD/YOie4PdO5bMpdwnpZbnNlYbs0uBwTIiIiotrEjgkRERFZgx0TIiIisoZ9g7VXAeZbuM0FgnNZmOYLwXE8nMvCtNw0fwE+k4+5CTi2iI9dY10Wt/FX3Efc5v79+wPuo20wbwdzJ9xqPZgeVzcdJ9NcOKb1Q62DYBrjdtufS2sRuW3TxpwOavhMtZ/w2unatWvQ2zTNTYNMeXam6xVh3gzeozAfcuTIkVr8wQcfaLHbPQ1z7XCeKBvxFxMiIiKyBjsmREREZA12TIiIiMgajXLwGGt8HD9+3LFObGxswG3gLMg4Vw7mgGBsmisHaw7gPDWYI4LjiPh8e0lJScD13fYB8xFwPNR2OAcStoEbt7lkLmUaM3Yb472Uaf4eHGPG74DHCM8jt3P5UjXJF8FztX379sb3EIUbXgt47eDy6lnug9mmqY5JsDldpvsDLsc8PqyHc+TIES3GOZHuuOMOLd63b5/jM/E9OAeRjfiLCREREVmDHRMiIiKyBjsmREREZI1GmWMycOBALf7HP/7hWMc05wiO/fl8Pi3GehimOVJMTGObuH1T7GbYsGFajPM09OzZ07gNm2Ce0OHDh7XYLZ8E68sgzOnAOgg4Rm06zm65PoG2jzkieF64zZFyKbc6Jngu4T7HxcUF3CZRbcD7D567eJ6mpqZqMc61I+KsQ2S6z5s+07TcdG2ZclQwd3HJkiVajPW2CgoKBHXv3l2LMf/QRvzFhIiIiKzBjgkRERFZgx0TIiIiskajzDHp0aOHFrs9e37ttdcG3AbmBuA2cG4brJ2CuQhYfwLXx/HWjh07ajGOdWIuws6dO8UEn6H/7rvvAu6D7bD+hmk8WUSkXbt2AZePGDFCizGXyFSnINi6CXhc8RjhGDXOe4PcckxMNXdMNX2IagNeO6b8DLw/eb1exzZNc1ch/Ey8XnEfcPumOdZwfbz+Mb8L9we/I7aZiLP+lFutE9vwFxMiIiKyBjsmREREZA12TIiIiMga7JgQERGRNRpl8uuZM2e0GCfkEzEnSf3hD3/Q4ieeeEKLjx49qsWmIlW4D5jkiMt37dqlxZhkdezYMS1+8MEHA36+iDPxE7+DKTHUNv369dPiZcuWabHbhHaYVIwwiTgtLU2LMfkMjxNOqGUqnIdwfZzM0TQJYU2KpeF3qG/HnRqGu+++W4uxECbeIwcMGKDFJ0+edGwTk9XxPmmaOBCvDVMyrOl6Nj20cOLECS3G4qC9e/fWYreJVq9kssO6xl9MiIiIyBrsmBAREZE12DEhIiIiazTKHJNu3bpp8ZNPPulYJzk5OeA2EhMTtXjp0qVanJOTo8VY1GbHjh1ajLkBOJaJBdf27t2rxThuOHPmTC2+5557xOQXv/iFFn/66adajGO4tsNJBzt06KDFOKGXiLmI3Pr160PfsTrkNkkhjnPjuda3b9/a3CUiV3hPxJw3nJgUr2+3fLFnn31WizEHBO+7mI+IOSCmSTtN28frESeDxZy02267TYu3bdsWcH9FREpLSwNuw0b8xYSIiIiswY4JERERWYMdEyIiIrJGo8wxweffhwwZEvI2o6KitPj//u//Aq6PY4GY24D1Kpo3bx7w83D5lejSpYsWT5w4MeRt2gRrjuzfv9+xDuYONTR4jEWc+Uk1qXVCVNt+9KMfafGf/vQnLcZ8DbdzGz300EOh75hF8FrFNhNxTihrqnVkA/5iQkRERNYIqmMyf/586du3r7Rp00batGkjAwYMkM8++8y/XCklWVlZ4vP5JDIyUtLT02X79u1h32kiIiJqmILqmCQkJMjs2bNl06ZNsmnTJrnzzjvlxz/+sb/zMWfOHJk7d6689tprsnHjRvF6vTJkyBApLy+vlZ0nIiKihiVCYTJDkNq1aye/+93vZNy4ceLz+SQzM1OmTZsmIiIVFRUSHx8vv/3tb11rhbgpKyuTmJgYefnllx3zgBAREZGdzp49K88++6yUlpY65iUKxhXnmFy8eFEWLVokZ86ckQEDBkhhYaEUFxdLRkaGfx2PxyODBw+WdevWXXY7FRUVUlZWpv0jIiKixinojsm2bdukdevW4vF4ZPz48fLRRx9J7969pbi4WEScleri4+P9y9zk5ORITEyM/19DfyqCiIiILi/ojkmPHj2koKBAvvrqK3nqqadk7NixWnl1LMGrlAo49fOMGTOktLTU/6+oqCjYXSIiIqIGIug6Ji1atJDu3buLiEhqaqps3LhRXn31VX9eSXFxsTZHQUlJieNXlEt5PB7xeDzB7gYRERE1QCHXMVFKSUVFhSQlJYnX65Xc3Fz/ssrKSsnLy5OBAweG+jFERETUCAT1i8nMmTNl2LBhkpiYKOXl5bJo0SJZs2aNLF++XCIiIiQzM1Oys7MlOTlZkpOTJTs7W6KiomTUqFG1tf9ERETUgATVMTl27JiMHj1ajh49KjExMdK3b19Zvny5v6T71KlT5ezZszJhwgQ5deqUpKWlyYoVKyQ6OrrGn1H99LJp+nkiIiKyR/Xf7RCrkIRexyTcDh06xCdziIiI6qmioiJJSEi44vdb1zGpqqqSI0eOSHR0tJSXl0tiYqIUFRWFVKylMSsrK2MbhohtGDq2YXiwHUPHNgzd5dpQKSXl5eXi8/mkSZMrT2G1bnbhJk2a+Hta1Y8ZV8/NQ1eObRg6tmHo2IbhwXYMHdswdG5tiLMZXwnOLkxERETWYMeEiIiIrGF1x8Tj8cjzzz/PAmwhYBuGjm0YOrZheLAdQ8c2DF1tt6F1ya9ERETUeFn9iwkRERE1LuyYEBERkTXYMSEiIiJrsGNCRERE1rC2YzJv3jxJSkqSli1bSkpKinz++ed1vUvWysnJkZtvvlmio6MlLi5O7r//ftm1a5e2jlJKsrKyxOfzSWRkpKSnp8v27dvraI/tl5OT45+YshrbsGYOHz4sjz/+uLRv316ioqLkxhtvlPz8fP9ytmNgFy5ckOeee06SkpIkMjJSunbtKi+88IJUVVX512Eb6tauXSv33Xef+Hw+iYiIkCVLlmjLa9JeFRUV8vTTT0tsbKy0atVKRowYIYcOHbqK36LuBWrH8+fPy7Rp0+SGG26QVq1aic/nkzFjxsiRI0e0bYSlHZWFFi1apJo3b67efPNNtWPHDjV58mTVqlUrdeDAgbreNSsNHTpULViwQH3zzTeqoKBADR8+XHXu3Fl9//33/nVmz56toqOj1Ycffqi2bdumHnnkEdWxY0dVVlZWh3tupw0bNqhrr71W9e3bV02ePNn/OtvQ7OTJk6pLly7qiSeeUOvXr1eFhYVq5cqVau/evf512I6Bvfjii6p9+/bq008/VYWFheqf//ynat26tXrllVf867ANdcuWLVOzZs1SH374oRIR9dFHH2nLa9Je48ePV506dVK5ublq8+bN6o477lD9+vVTFy5cuMrfpu4EasfTp0+ru+++W73//vtq586d6ssvv1RpaWkqJSVF20Y42tHKjsktt9yixo8fr73Ws2dPNX369Drao/qlpKREiYjKy8tTSilVVVWlvF6vmj17tn+dc+fOqZiYGPWXv/ylrnbTSuXl5So5OVnl5uaqwYMH+zsmbMOamTZtmho0aNBll7MdzYYPH67GjRunvfbAAw+oxx9/XCnFNjTBP6g1aa/Tp0+r5s2bq0WLFvnXOXz4sGrSpIlavnz5Vdt3m7h18NCGDRuUiPh/NAhXO1o3lFNZWSn5+fmSkZGhvZ6RkSHr1q2ro72qX0pLS0VEpF27diIiUlhYKMXFxVqbejweGTx4MNsUTJw4UYYPHy5333239jrbsGY++eQTSU1NlZ/85CcSFxcn/fv3lzfffNO/nO1oNmjQIPn3v/8tu3fvFhGRr7/+Wr744gu55557RIRtGKyatFd+fr6cP39eW8fn80mfPn3YpgGUlpZKRESEXHPNNSISvna0bhK/48ePy8WLFyU+Pl57PT4+XoqLi+tor+oPpZRMmTJFBg0aJH369BER8bebW5seOHDgqu+jrRYtWiSbN2+WjRs3OpaxDWtm3759Mn/+fJkyZYrMnDlTNmzYIL/85S/F4/HImDFj2I41MG3aNCktLZWePXtK06ZN5eLFi/LSSy/Jo48+KiI8F4NVk/YqLi6WFi1aSNu2bR3r8O+Ou3Pnzsn06dNl1KhR/on8wtWO1nVMqlXPLFxNKeV4jZwmTZokW7dulS+++MKxjG16eUVFRTJ58mRZsWKFtGzZ8rLrsQ0Dq6qqktTUVMnOzhYRkf79+8v27dtl/vz5MmbMGP96bMfLe//99+Xdd9+VhQsXyvXXXy8FBQWSmZkpPp9Pxo4d61+PbRicK2kvtqm78+fPy8iRI6WqqkrmzZtnXD/YdrRuKCc2NlaaNm3q6F2VlJQ4eryke/rpp+WTTz6R1atXS0JCgv91r9crIsI2DSA/P19KSkokJSVFmjVrJs2aNZO8vDz54x//KM2aNfO3E9swsI4dO0rv3r2113r16iUHDx4UEZ6LNfGrX/1Kpk+fLiNHjpQbbrhBRo8eLc8884zk5OSICNswWDVpL6/XK5WVlXLq1KnLrkP/c/78eXn44YelsLBQcnNz/b+WiISvHa3rmLRo0UJSUlIkNzdXez03N1cGDhxYR3tlN6WUTJo0SRYvXiyrVq2SpKQkbXlSUpJ4vV6tTSsrKyUvL49t+v/dddddsm3bNikoKPD/S01Nlccee0wKCgqka9eubMMauPXWWx2Pqu/evVu6dOkiIjwXa+KHH36QJk30W3PTpk39jwuzDYNTk/ZKSUmR5s2ba+scPXpUvvnmG7bpJao7JXv27JGVK1dK+/btteVha8cgknSvmurHhd966y21Y8cOlZmZqVq1aqX2799f17tmpaeeekrFxMSoNWvWqKNHj/r//fDDD/51Zs+erWJiYtTixYvVtm3b1KOPPtqoHy+siUufylGKbVgTGzZsUM2aNVMvvfSS2rNnj/r73/+uoqKi1Lvvvutfh+0Y2NixY1WnTp38jwsvXrxYxcbGqqlTp/rXYRvqysvL1ZYtW9SWLVuUiKi5c+eqLVu2+J8WqUl7jR8/XiUkJKiVK1eqzZs3qzvvvLPRPS4cqB3Pnz+vRowYoRISElRBQYH2t6aiosK/jXC0o5UdE6WU+vOf/6y6dOmiWrRooW666Sb/o6/kJCKu/xYsWOBfp6qqSj3//PPK6/Uqj8ejbr/9drVt27a62+l6ADsmbMOaWbp0qerTp4/yeDyqZ8+e6o033tCWsx0DKysrU5MnT1adO3dWLVu2VF27dlWzZs3Sbv5sQ93q1atd74Fjx45VStWsvc6ePasmTZqk2rVrpyIjI9W9996rDh48WAffpu4EasfCwsLL/q1ZvXq1fxvhaMcIpZQK9uccIiIiotpgXY4JERERNV7smBAREZE12DEhIiIia7BjQkRERNZgx4SIiIiswY4JERERWYMdEyIiIrIGOyZERERkDXZMiIiIyBrsmBAREZE12DEhIiIia7BjQkRERNb4f5TKhGx/nrQRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used TorchVision and Matplotlib to create a visual grid of a minibatch of our input data. Below, we use the `add_image()` call on `SummaryWriter` to log the image for consumption by TensorBoard, and we also call `flush()` to make sure it's written to disk right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you start TensorBoard at the command line and open it in a new browser tab (usually at [localhost:6006](localhost:6006)), you should see the image grid under the IMAGES tab.\n",
    "\n",
    "## Graphing Scalars to Visualize Training\n",
    "\n",
    "TensorBoard is useful for tracking the progress and efficacy of your training. Below, we'll run a training loop, track some metrics, and save the data for TensorBoard's consumption.\n",
    "\n",
    "Let's define a model to categorize our image tiles, and an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()        \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a single epoch, and evaluate the training vs. validation set losses every 1000 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch 1000\n",
      "Batch 2000\n",
      "Batch 3000\n",
      "Batch 4000\n",
      "Batch 5000\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        input, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(input)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:     # Every thosand mini batch\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check againt the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            net.train(False) # Don't need to track gradient for validation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Turn gradients back on for training\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation': avg_vloss},\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print(\"Finish Training\")\n",
    "writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to your open TensorBoard and have a look at the SCALARS tab.\n",
    "\n",
    "## Visualizing Your Model\n",
    "TensorBoard can also be used to examine the data flow within your model. To do this, call the `add_graph()` method with a model and sample input. When you open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you switch over to TensorBoard, you should see a GRAPHS tab. Double-click the \"NET\" node to see the layers and data flow within your model.\n",
    "\n",
    "## Visualizing Your Dataset with Embeddings\n",
    "\n",
    "The 28-by-28 image tiles we're using can be modeled as 784-dimensional vectors (28 * 28 = 784). It can be instructive to project this to a lower-dimensional representation. The `add_embedding()` method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart. The `add_embedding()` method does this automatically by projecting to the three dimensions with highest variance.\n",
    "\n",
    "Below, we'll take a sample of our data, and generate such an embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadam/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/sadam/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(False)\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
