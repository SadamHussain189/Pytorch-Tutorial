{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                    # for all thing pytorch\n",
    "import torch.nn as nn           # for torch.nn.Module, the parent object for PyTorch models\n",
    "import torch.nn.functional as F # for the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below code LeNet5 one of the earlist convolutionnal neural nets, and one of the driver of the explosion in Deep Learning. it was build to read samll images of hand written numbers(MNIST dataset), and correctly classify which digit was  represented in the image.\n",
    "Here's the abridget version of how it works:\n",
    "\n",
    "    . Layer C1 is a convolutional layer, meaning that it scans the input image for feature it learned during training. its outputs a map of where it saw each of its learned feature in the image. This 'activation map' is downsampled in layer S2.\n",
    "\n",
    "    . Layer C3 is another convolution layer, this time scanning C1's activation map for combination of feature. it also put out an activation map describing the spatial location of these feature combination which is dowsampled in layer S4.\n",
    "    \n",
    "    . Finally, the fully connected layer at the ned F5,F6 and OUTPUT, are a classifier the take the final activation map, and classifies it into one of ten bins representing the 10 digits.\n",
    "\n",
    "How we express this sample neural networks in code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # input the image channel (black & white), 6 output channels, 3x3 squares convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16, 6, 6, 120) # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # if the size is square you can only specify a single number \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimension except the batch dimeansion\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates the structure of typical pytorch model:\n",
    "    . it inherits from torch.nn.Module  modules may be nested in fact, even the conv2d and linear layer classes inherit from torch.nn.Module.\n",
    "\n",
    "    . A model will have an __init__() function, where it instantiate its layer, and load any data artifacts it might need (e.g.. an NLP model might load a vocabulary).\n",
    "\n",
    "    . A model will have forward() function. This is where the actual computation happens: An input it passed through the network layers and various function to generate output.\n",
    "\n",
    "    . Other than that, you can build out your model class like any other python class, adding whatever properties and method you need to support your model's computation\n",
    "\n",
    "let's instatiate this object and run a sample input through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
